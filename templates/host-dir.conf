# DO NOT EDIT - Managed by Puppet
#
# Bacula Director Per-Host Configuration
#   for <%= safe_client_hostname %>
#   via <%= safe_director_name -%>:director (<%= safe_director_hostname -%>)
#    to <%= safe_storage_name -%>:storage:<%= safe_client_name -%> (<%= safe_storage_hostname -%>)
#
# These files will be important dynamically by bacula-dir.conf when
# put into the /etc/bacula/bacula-dir.d directory.

<%  # Work out if we need to create a custom fileset for this client. We
    # do this here so we can set the correct name in the JobDefs value
    # under the Job for this client.
    if ((has_variable?('bacula_backup_includes') and bacula_backup_includes.class == Array and bacula_backup_includes.length > 0) or
        (has_variable?('bacula_backup_excludes') and bacula_backup_excludes.class == Array and bacula_backup_excludes.length > 0))
       do_fileset = true
       # We use the noHome version of the template as a base - if the
       # $bacula_backup_dohome variable is set, we'll add it into the
       # includes array so that it's processed correctly.
       if (safe_backup_dohome == 'withHome')
         bacula_backup_includes << '/home'
       end
    else
       do_fileset = false
    end
-%>

# Configure our client so that the Director can contact it
Client {
  Name = "<%= safe_client_hostname -%>"
  Password = "<%= bacula_server_password -%>"
  Address = <%= safe_client_hostname %>
  # This will be managed by the default catalog
  Catalog = "<%= safe_director_name -%>:sqlite"
  # Any files backed up will only be kept for maximum of
  # around 1 month, so we'll set retention of that information
  # to a maximum of 6 weeks
  File Retention = 6 Weeks
  # However, we'll keep a log of all the work done on the server
  # for around a year so we can keep an eye on it and see
  # general progression or changes over time.
  Job Retention = 1 Year
  # Get rid of any data or files as they expire.
  Auto Prune = Yes
}

# Each client will have a dedicated Device on the Storage Daemon,
# so that we can support concurrent backups and have dedicated
# space for it's volumes (which will be managed by the Pools below)
Storage {
  Name = "<%= safe_storage_name -%>:storage:<%= safe_client_name -%>"
  Address = <%= safe_storage_hostname %>
  Password  = "<%= bacula_server_password -%>"
  Device = "<%= safe_client_hostname -%>"
  Media Type = File
}

# Create the Job which will back up this client and set the schedule
Job {
  Name = "<%= safe_client_hostname -%>"
  Priority = <%= safe_priority %>
  JobDefs = "Basic:<%= safe_backup_dohome -%>:on<%= safe_backup_onday.capitalize -%>"
  Client = "<%= safe_client_hostname -%>"
<% if do_fileset -%>
  # Override the FileSet for this client as it has custom requirements
  FileSet = "<%= safe_client_name.capitalize -%>:<%= safe_backup_dohome -%>"
<% end -%>
  # Override the defaults for this Job so that it goes to the correct
  # Storage Daemon and uses the correct pool for naming and volume
  # management (retention, pruning & recycling)
  Storage = "<%= safe_storage_name -%>:storage:<%= safe_client_name -%>"
  Full Backup Pool = "<%= safe_storage_name -%>:pool:<%= safe_client_name -%>:weekly"
  Differential Backup Pool = "<%= safe_storage_name -%>:pool:<%= safe_client_name -%>:weekly"
  Incremental Backup Pool = "<%= safe_storage_name -%>:pool:<%= safe_client_name -%>:daily"
  # Make sure that duplicate jobs are not lined up should there be a slow
  # or long job, but when there are two jobs activated, make sure the most
  # import one (e.g. Full over Incremental) is the one thats kept
  Allow Duplicate Jobs = No
  Cancel Lower Level Duplicates = Yes
  # If there are duplicate jobs at the same level (e.g. Multiple Full),
  # either kill the oldest still-queued duplicate, or if the duplicate is
  # running, kill the one we've just added to the queue; we should only
  # ever kill a running job if its more important above (see above)
  Cancel Queued Duplicates = Yes
  Cancel Running Duplicates = No
  # Allow jobs with higher priority to run even if lower-priorty jobs are
  # already running. However, this will not allow lower priority jobs to run
  # while there are still higher-priority active
  Allow Mixed Priority = Yes
}

# Create two pools of Volumes to work with: One will be for Weekly
# backups, which we'll keep a months worth, and Daily, those kept for a week.
Pool {
  Name = "<%= safe_storage_name -%>:pool:<%= safe_client_name -%>:weekly"
  # All Volumes will have the format hostname.type.date.time to ensure they
  # are kept unique throughout the operation and also aid quick analysis
  Label Format = "<%= safe_client_name -%>.daily.${Counter<%= safe_client_name.capitalize -%>Weekly+:p/3/0/r}"
  Pool Type = Backup
  # Keep using Volumes as they expire, and delete the ones
  # that are no longer required or expire.
  Recycle = Yes
  Auto Prune = Yes
  # The point of calculation for retention is the time the
  # volume was last written, therefore we'll knock 36 hours
  # off 5 weeks to ensure correct rotation: (5*7*24)-36 = 804
  Volume Retention = 804 Hours
  # For Weekly Backups, we want to keep 5 copies: A Full backup
  # is done monthly, and upto 4 differential backups through
  # the course of the rest of the month. However, to allow for
  # first time backups, or changes in FileSet's, we'll allow for
  # an additional volume.
  Maximum Volumes = 6
  # A Volume should not be appended; either created when
  # needed or overwritten when too old
  Maximum Volume Jobs = 1
}

Pool {
  Name = "<%= safe_storage_name -%>:pool:<%= safe_client_name -%>:daily"
  Label Format = "<%= safe_client_name -%>.daily.${Counter<%= safe_client_name.capitalize -%>Daily+:p/3/0/r}"
  Pool Type = Backup
  Recycle = Yes
  Auto Prune = Yes
  # Like weekly backups, we'll move through a set number
  # of volumes, which should be no more than 7 days old
  # and we need no more than 6 of them (7th day is the full
  # backup).
  # The point of calculation for retention is the time the
  # volume was last written, therefore we'll knock 12 hours
  # off 7 days to ensure correct rotation: (7*24)-12 = 156
  Volume Retention = 156 Hours
  Maximum Volumes = 6
  # Again, create or overwrite, not append.
  Maximum Volume Jobs = 1
}

# Create a pair of Counter's which will be used to label the volumes as they're
# created on the system.
Counter {
  Name    = "Counter<%= safe_client_name.capitalize -%>Daily"
  Minimum = 1
  Catalog = "<%= safe_director_name -%>:sqlite"
}

Counter {
  Name    = "Counter<%= safe_client_name.capitalize -%>Weekly"
  Minimum = 1
  Catalog = "<%= safe_director_name -%>:sqlite"
}

<% if do_fileset -%>
# This client requires a custom FileSet as there are additional locations
# to be backed up, or excluded, compared with the Basic FileSet
FileSet {
  Name = "<%= safe_client_name.capitalize -%>:<%= safe_backup_dohome -%>"
  Include {
    Options {
      Signature   = MD5
      Compression = GZIP
    }

    File = /boot
    File = /etc
    File = /usr/local
    File = /var
    File = /opt
    File = /srv
<% bacula_backup_includes.each do |location| -%>
    File = <%= location %>
<% end if has_variable?('bacula_backup_includes') -%>
  }

  Exclude {
    File = /var/cache
    File = /var/tmp
    File = /var/lib/dpkg
    File = /var/lib/puppet
    File = /var/lib/mysql
    File = /var/lib/postgresql
    File = /var/lib/ldap
    File = /var/lib/bacula
<% bacula_backup_excludes.each do |location| -%>
    File = <%= location %>
<% end if has_variable?('bacula_backup_excludes') -%>
  }
}
<% end %>
